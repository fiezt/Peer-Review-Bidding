{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import functools\n",
    "import pickle\n",
    "import multiprocess\n",
    "from sklearn.utils import shuffle\n",
    "from algorithms import Problem\n",
    "import utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_fig = True\n",
    "save_fig = True\n",
    "save_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr_data = np.load('iclr2018_all.npz')\n",
    "iclr_similarity = iclr_data['similarity_matrix']\n",
    "iclr_author_mask = iclr_data['mask_matrix']\n",
    "\n",
    "row_idx = np.where(iclr_author_mask == 1)[0]\n",
    "col_idx = np.where(iclr_author_mask == 1)[1]\n",
    "iclr_similarity[row_idx, col_idx] = 0\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'UAI_FIGS_ICLR_FINAL4')\n",
    "data_dir = os.path.join(os.getcwd(), 'UAI_DATA_ICLR_FINAL4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain and Bidding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain functions for paper-side gain.                     \n",
    "sqrt = lambda d: np.sqrt(d)\n",
    "minimum_3 = lambda d: np.minimum(d, 3)\n",
    "minimum_5 = lambda d: np.minimum(d, 5)\n",
    "minimum_6 = lambda d: np.minimum(d, 6)\n",
    "minimum_10 = lambda d: np.minimum(d, 10)\n",
    "\n",
    "# Gain functions for reviewer-side gain.\n",
    "def DCG(s, pi=None): \n",
    "    if pi is None:\n",
    "        return (2.**(s)-1)\n",
    "    else:\n",
    "        return (2.**(s)-1)/np.log2(pi + 1)\n",
    "    \n",
    "def DCG_sqrt(s, pi=None): \n",
    "    if pi is None: \n",
    "        return (2.**(s)-1) \n",
    "    else: \n",
    "        return (2.**(s)-1)/np.sqrt(pi)\n",
    "\n",
    "# Bidding functions.\n",
    "def bid_log(s, pi=None): \n",
    "    if pi is None:\n",
    "        return s\n",
    "    else:\n",
    "        return s/np.log2(pi + 1)\n",
    "    \n",
    "def bid_sqrt(s, pi=None): \n",
    "    if pi is None:\n",
    "        return s\n",
    "    else:\n",
    "        return s/np.sqrt(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Simulate All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_all(s_list, g_p, g_r, f, f_tilde, noise, hyper, special, stop, poisson, subset, seed, verbose=True):\n",
    "\n",
    "    start = time.time()\n",
    "    super_mean_heuristic = Problem(s=s_list, g_p=g_p, g_r=g_r, f=f, f_tilde=f_tilde, noise=noise, \n",
    "                                     hyper=hyper, special=special, stop=stop, poisson=poisson, subset=subset)\n",
    "    super_mean_heuristic.simulate(super_mean_heuristic.super_mean_heuristic_policy, seed)\n",
    "    end = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print('finish mean heuristic', end-start)\n",
    "\n",
    "    start = time.time()\n",
    "    super_zero_heuristic = Problem(s=s_list, g_p=g_p, g_r=g_r, f=f, f_tilde=f_tilde, noise=noise, hyper=hyper, \n",
    "                                   special=special, stop=stop, poisson=poisson, subset=subset)\n",
    "    super_zero_heuristic.simulate(super_zero_heuristic.super_zero_heuristic_policy, seed)\n",
    "    end = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print('finish zero heuristic', end-start)\n",
    "\n",
    "    start = time.time()\n",
    "    sim = Problem(s=s_list, g_p=g_p, g_r=g_r, f=f, f_tilde=f_tilde, noise=noise, hyper=hyper, \n",
    "                  special=special, stop=stop, poisson=poisson, subset=subset)\n",
    "    sim.simulate(sim.sim_policy, seed)\n",
    "    end = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print('finish sim', end-start)\n",
    "\n",
    "    start = time.time()\n",
    "    bid = Problem(s=s_list, g_p=g_p, g_r=g_r, f=f, f_tilde=f_tilde, noise=noise, hyper=hyper, \n",
    "                  special=special, stop=stop, poisson=poisson, subset=subset)\n",
    "    bid.simulate(bid.bid_policy, seed)\n",
    "    end = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print('finish bid', end-start)\n",
    "\n",
    "    start = time.time()\n",
    "    random = Problem(s=s_list, g_p=g_p, g_r=g_r, f=f, f_tilde=f_tilde, noise=noise, hyper=hyper, \n",
    "                     special=special, stop=stop, poisson=poisson, subset=subset)\n",
    "    random.simulate(random.random_policy, seed)\n",
    "    end = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print('finish random', end-start)\n",
    "\n",
    "    algs = [super_mean_heuristic, super_zero_heuristic, sim, bid, random]\n",
    "\n",
    "    return algs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Set 1: Standard Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_range = np.arange(0, 1.1, .2)\n",
    "\n",
    "hyper_range_set = [hyper_range]\n",
    "gain_function_set = [minimum_6]\n",
    "name1 = 'min6_normal_all'\n",
    "name2 = 'min6_normal_gain'\n",
    "\n",
    "num = 0\n",
    "for g_p, hyper_range in zip(gain_function_set, hyper_range_set):\n",
    "\n",
    "    full_all_data = []\n",
    "    full_gain_data = []\n",
    "\n",
    "    for hyper in hyper_range:\n",
    "        g_r = DCG\n",
    "        f = bid_log\n",
    "        f_tilde = bid_log\n",
    "        noise = 0\n",
    "        special = True\n",
    "        stop = lambda x: x\n",
    "        poisson = False\n",
    "        subset = False\n",
    "        seed = 0\n",
    "        count = 20        \n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        s_list = [shuffle(iclr_similarity) for _ in xrange(count)]\n",
    "        \n",
    "        algs = simulate_all(s_list, g_p, g_r, f, f_tilde, noise, hyper, special, stop, poisson, subset, seed, verbose=True)\n",
    "\n",
    "        all_data = [(algs[i].gain_mean, algs[i].p_gain_mean, algs[i].r_gain_mean, algs[i].r_gain_unweighted_mean, algs[i].bid_history) for i in xrange(len(algs))]\n",
    "        gain_data = [(algs[i].gain_mean, algs[i].gain_se) for i in xrange(len(algs))]\n",
    "\n",
    "        full_all_data.append(all_data)\n",
    "        full_gain_data.append(gain_data)\n",
    "        \n",
    "    hyper_range = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    utils.sweep_comparison_plot(full_gain_data, hyper_range, 'Tradeoff parameter $\\lambda$', os.path.join(save_dir, 'min6.pdf'), show_fig, save_fig)\n",
    "    utils.sweep_comparison_plot_sim_base(full_gain_data, hyper_range, 'Tradeoff parameter $\\lambda$', os.path.join(save_dir, 'min6_base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    hyper_index = 4\n",
    "    index = None\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2, 3, 4]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'min6_bids.pdf'), show_fig, save_fig)\n",
    "\n",
    "    hyper_index = 4\n",
    "    index = None\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'min6_bids_base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if save_data:\n",
    "        pickle.dump(full_all_data, open(os.path.join(data_dir, name1+str(num)+'.p'), 'wb'))\n",
    "        pickle.dump(full_gain_data, open(os.path.join(data_dir, name2+str(num)+'.p'), 'wb'))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Set 2: Varying Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_range1 = np.arange(0.0, 0.6, 0.1)\n",
    "hyper_range2 = np.arange(0, 1.5, .2)\n",
    "\n",
    "hyper_range_set = [hyper_range1, hyper_range2]\n",
    "parameter_sets = [(sqrt, bid_log, DCG), (minimum_6, bid_sqrt, DCG_sqrt)]\n",
    "name1 = 'param_vary_all'\n",
    "name2 = 'param_vary_gain'\n",
    "\n",
    "num = 0\n",
    "for param_set, hyper_range in zip(parameter_sets, hyper_range_set):\n",
    "\n",
    "    full_all_data = []\n",
    "    full_gain_data = []\n",
    "\n",
    "    for hyper in hyper_range:\n",
    "        g_p = param_set[0]\n",
    "        g_r = param_set[2]\n",
    "        f = param_set[1]\n",
    "        f_tilde = param_set[1]\n",
    "        noise = 0\n",
    "        special = True\n",
    "        stop = lambda x: x\n",
    "        poisson = False\n",
    "        subset = False\n",
    "        seed = 0\n",
    "        count = 20        \n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        s_list = [shuffle(iclr_similarity) for _ in xrange(count)]\n",
    "        \n",
    "        algs = simulate_all(s_list, g_p, g_r, f, f_tilde, noise, hyper, special, stop, poisson, subset, seed, verbose=True)\n",
    "\n",
    "        all_data = [(algs[i].gain_mean, algs[i].p_gain_mean, algs[i].r_gain_mean, algs[i].r_gain_unweighted_mean, algs[i].bid_history) for i in xrange(len(algs))]\n",
    "        gain_data = [(algs[i].gain_mean, algs[i].gain_se) for i in xrange(len(algs))]\n",
    "\n",
    "        full_all_data.append(all_data)\n",
    "        full_gain_data.append(gain_data)\n",
    "        \n",
    "    if num == 0:\n",
    "        hyper_range = np.array([0.0, 0.1, 0.2, 0.3, 0.4, 0.6])\n",
    "    elif num == 1:\n",
    "        hyper_range = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4])\n",
    "\n",
    "    utils.sweep_comparison_plot(full_gain_data, hyper_range, 'Tradeoff parameter $\\lambda$', os.path.join(save_dir, 'param_set' + str(num) + '.pdf'), show_fig, save_fig)\n",
    "    utils.sweep_comparison_plot_sim_base(full_gain_data, hyper_range, 'Tradeoff parameter $\\lambda$', os.path.join(save_dir,'param_set' + str(num) + 'base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if num == 0:\n",
    "        hyper_index = 4\n",
    "    elif num == 1:\n",
    "        hyper_index = 6\n",
    "    index = None\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2, 3, 4]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'param_set' + str(num) + 'bids.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if num == 0:\n",
    "        hyper_index = 4\n",
    "    elif num == 1:\n",
    "        hyper_index = 6\n",
    "    index = None\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'param_set' + str(num) + 'bids_base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if save_data:\n",
    "        pickle.dump(full_all_data, open(os.path.join(data_dir, name1+str(num)+'.p'), 'wb'))\n",
    "        pickle.dump(full_gain_data, open(os.path.join(data_dir, name2+str(num)+'.p'), 'wb'))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Set 3: Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_range = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "parameter_sets = [(bid_sqrt, 0, lambda x: x, False, False), (bid_log, 0.01, lambda x:x, False, False), (bid_log, 0, lambda x:int(3*x/4), False, False), (bid_log, 0, lambda x:x, True, False), (bid_log, 0, lambda x:x, False, True)]\n",
    "name1 = 'robust_all'\n",
    "name2 = 'robust_gain'\n",
    "\n",
    "num = 4\n",
    "for param_set in parameter_sets[-1:]:\n",
    "\n",
    "    full_all_data = []\n",
    "    full_gain_data = []\n",
    "\n",
    "    for hyper in hyper_range:\n",
    "        g_p = minimum_6\n",
    "        g_r = DCG\n",
    "        f = bid_log\n",
    "        f_tilde = param_set[0]\n",
    "        noise = param_set[1]\n",
    "        special = True\n",
    "        stop = param_set[2]\n",
    "        poisson = param_set[3]\n",
    "        subset = param_set[4]\n",
    "        seed = 0\n",
    "        count = 20   \n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        s_list = [shuffle(iclr_similarity) for _ in xrange(count)]\n",
    "        \n",
    "        algs = simulate_all(s_list, g_p, g_r, f, f_tilde, noise, hyper, special, stop, poisson, subset, seed, verbose=True)\n",
    "\n",
    "        all_data = [(algs[i].gain_mean, algs[i].p_gain_mean, algs[i].r_gain_mean, algs[i].r_gain_unweighted_mean, algs[i].bid_history) for i in xrange(len(algs))]\n",
    "        gain_data = [(algs[i].gain_mean, algs[i].gain_se) for i in xrange(len(algs))]\n",
    "\n",
    "        full_all_data.append(all_data)\n",
    "        full_gain_data.append(gain_data)\n",
    "        \n",
    "    utils.sweep_comparison_plot(full_gain_data, hyper_range, 'Tradeoff parameter $\\lambda$', os.path.join(save_dir, 'robust' + str(num) + '.pdf'), show_fig, save_fig)\n",
    "    utils.sweep_comparison_plot_sim_base(full_gain_data, hyper_range, 'Tradeoff parameter $\\lambda$', os.path.join(save_dir,'robust' + str(num) + 'base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    hyper_index = 4\n",
    "    index = None\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2, 3, 4]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'robust' + str(num) + 'bids.pdf'), show_fig, save_fig)\n",
    "\n",
    "    hyper_index = 4\n",
    "    index = None\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'robust' + str(num) + 'bids_base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if save_data:\n",
    "        pickle.dump(full_all_data, open(os.path.join(data_dir, name1+str(num)+'.p'), 'wb'))\n",
    "        pickle.dump(full_gain_data, open(os.path.join(data_dir, name2+str(num)+'.p'), 'wb'))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Set 4: Varying Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "s_func_block = lambda pair: np.random.uniform(0, .05, (pair[0], pair[1])) +block_diag(*[np.random.uniform(.7, .7)*np.ones((25,25)) for i in range(int(pair[0]/25))])\n",
    "\n",
    "s_func_inter = lambda pair: np.vstack([np.hstack([.17*np.ones((int(pair[0]/2), int(.4*pair[1]))), .005*np.ones((int(pair[0]/2), int(.4*pair[1]))), .085*np.ones((int(pair[0]/2), int(.2*pair[1])))]), \n",
    "                            np.hstack([.005*np.ones((int(pair[0]/2), int(.4*pair[1]))), .17*np.ones((int(pair[0]/2), int(.4*pair[1]))), .085*np.ones((int(pair[0]/2), int(.2*pair[1])))])])\n",
    "\n",
    "s_func_beta = lambda pair: np.random.beta(1, 15, pair)\n",
    "s_func_low_rank = lambda pair: np.vstack([np.dot(np.ones(int(pair[0]/10)).reshape(-1, 1), np.random.beta(i, 60, pair[1]).reshape(1, -1)) for i in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = 'vary_sim_all'\n",
    "name2 = 'vary_sim_gain'\n",
    "param_list = [(250,250), (500,500), (750,750), (1000,1000)]\n",
    "s_func_list = [s_func_beta, s_func_low_rank, s_func_block, s_func_inter]\n",
    "\n",
    "num = 0\n",
    "for s_func in s_func_list:\n",
    "\n",
    "    full_all_data = []\n",
    "    full_gain_data = []\n",
    "\n",
    "    for pair in param_list:\n",
    "        g_p = minimum_6\n",
    "        g_r = DCG\n",
    "        f = bid_log\n",
    "        f_tilde = bid_log\n",
    "        hyper = 0.8\n",
    "        noise = 0\n",
    "        special = True\n",
    "        stop = lambda x: x\n",
    "        poisson = False\n",
    "        subset = False\n",
    "        seed = 0\n",
    "        count = 20      \n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        s_list = [s_func(pair) for _ in xrange(count)]\n",
    "        \n",
    "        algs = simulate_all(s_list, g_p, g_r, f, f_tilde, noise, hyper, special, stop, poisson, subset, seed, verbose=True)\n",
    "\n",
    "        all_data = [(algs[i].gain_mean, algs[i].p_gain_mean, algs[i].r_gain_mean, algs[i].r_gain_unweighted_mean, algs[i].bid_history) for i in xrange(len(algs))]\n",
    "        gain_data = [(algs[i].gain_mean, algs[i].gain_se) for i in xrange(len(algs))]\n",
    "\n",
    "        full_all_data.append(all_data)\n",
    "        full_gain_data.append(gain_data)\n",
    "        \n",
    "    hyper_range = np.array([250, 500, 750, 1000])\n",
    "    utils.sweep_comparison_plot(full_gain_data, hyper_range, 'Number of reviewers and papers', os.path.join(save_dir, 'matrix' + str(num) + '.pdf'), show_fig, save_fig)\n",
    "    utils.sweep_comparison_plot_sim_base(full_gain_data, hyper_range, 'Number of reviewers and papers', os.path.join(save_dir,'matrix' + str(num) + 'base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if num == 3:\n",
    "        index = int(param_list[hyper_index][0]*.8)\n",
    "    else:\n",
    "        index = None\n",
    "    hyper_index = 2\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2, 3, 4]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'matrix' + str(num) + 'bids.pdf'), show_fig, save_fig)\n",
    "\n",
    "    hyper_index = 2\n",
    "    intervals = [(0, 2), (3, 5), (6, 8), (9, 10)]\n",
    "    alg_set = [0, 1, 2]\n",
    "    endpoint = False\n",
    "    bid_count_data = full_all_data\n",
    "    utils.plot_bid_count_data(bid_count_data, hyper_index, intervals, alg_set, endpoint, index, os.path.join(save_dir, 'matrix' + str(num) + 'bids_base.pdf'), show_fig, save_fig)\n",
    "\n",
    "    if save_data:\n",
    "        pickle.dump(full_all_data, open(os.path.join(data_dir, name1+str(num)+'.p'), 'wb'))\n",
    "        pickle.dump(full_gain_data, open(os.path.join(data_dir, name2+str(num)+'.p'), 'wb'))\n",
    "    num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python27",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
